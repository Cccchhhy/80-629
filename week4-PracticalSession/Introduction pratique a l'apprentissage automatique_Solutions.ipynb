{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATH80629 automne 2020\n",
    "=======\n",
    "\n",
    "Tutoriel: Introduction pratique à l'apprentissage automatique (avec le solutionnaire)\n",
    "=============\n",
    "\n",
    "Ce tutoriel se veut une courte introduction à l'utilisation pratique de l'apprentissage automatique (machine learning).\n",
    "\n",
    "Nous supposons que l'étudiant a déjà une compréhension des fondamentaux du domaine et nous nous travaillerons les concepts d'apprentissage supervisé avec les libraires python `scikit-learn`, `pandas` et `numpy`.\n",
    "\n",
    "Ce document propose les trois étapes suivantes: \n",
    "1. chargement et prétraitement des données, \n",
    "2. estimations de différents modèles sur quelques versions du jeu de données,\n",
    "3. comparaison des résultats.\n",
    "\n",
    "Ce tutoriel ne se veut pas exhaustif. Lorsque les notions abordées requièrent plus de précisions, nous proposons des compléments d'information externes. De plus, il y a quelques références plus générales sur les librairies à la fin du tutoriel.  \n",
    "\n",
    "### Auteur: \n",
    "- Laurent Charlin <lcharlin@gmail.com>\n",
    "\n",
    "### Table des matières\n",
    "\n",
    "- [Section 0. Introduction](#introduction)\n",
    "- [Section 1. Prétraitement des données](#pre-processing)\n",
    "- [Section 2. Modélisation](#modelling)\n",
    "- [Section 3. Conclusions](#concluding-remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "### Section 0. Introduction\n",
    "\n",
    "Plutôt que d'utiliser une tâche bidon ou un jeu de données synthétiques, nous utiliserons l'exemple d'un système de recommandation pour explorer les bases pratiques de l'apprentissage automatique. Notre tâche sera donc de recommander des films à des utilisateurs (vous pouvez imaginer que vous êtes ingénieur chez Netflix). Nous modéliserons les préférences pour les films d'utilisateurs venant d'un jeu de données publique (Movielens 1M). Notre modèle apprendra à prédire les notes (*ratings*) des utilisateurs pour des films à partir de données sociodémographiques des utilisateurs ainsi que des *tags* des films.\n",
    "\n",
    "Formellement, nous nous intéressons donc à apprendre les paramètres de la fonction:  \n",
    "\n",
    "$$ r_{um} = f_\\theta(x_u, x_m)$$ \n",
    "où \n",
    "- $u$ indexe les utilisateurs \n",
    "- $m$ indexe les items\n",
    "- $r_{um}$ est la note (rating) de l'utilisateur u pour le film m -- c'est la variable dépendante\n",
    "- $f_\\theta$ est le modèle paramétré par $\\theta$. Par exemple, un modèle de régression linéaire avec des coefficients $\\theta$\n",
    "- $x_u$ sont les attributs de l'utilisateur u (p.ex., l'âge et l'emploi de l'utilisateur)\n",
    "- $x_m$ sont les attributs du film m (p.ex., les *tags* données au film)\n",
    "\n",
    "La fonction $f$ peut être modélisée de plusieurs façons. Aujourd'hui, nous prendrons pour hypothèse que la tâche de recommandation en est une de prédiction de notes et donc c'est un problème de régression. Nous comparerons plusieurs modèles linéaires (régression linéaire) et non-linéaires (comme un réseau de neurones).\n",
    "\n",
    "\n",
    "### Terminologie en Apprentissage Automatique \n",
    "\n",
    "Rappelons nous que nous utilisons une définition de l'apprentissage automatique ayant trois concepts:\n",
    "\n",
    "1. Tâche / Task (T)\n",
    "2. Expérience / Experience (E)\n",
    "3. Mesure de performance / Performance measure (P).\n",
    "\n",
    "(une description complète de ces trois concepts est donnée au [Ch. 5 du livre Deep Learning](https://www.deeplearningbook.org/contents/ml.html))\n",
    "\n",
    "L'intuition c'est que la tâche (T) c'est le problème que l'on veut résoudre (p.ex., classification, régression, détection d'anomalies), l'expérience (E) c'est le type de données disponibles et comment le modèle y accède (p.ex., avec ou sans étiquettes, en flux ou d'un coup). Finalement la performance (P) c'est la qualité du modèle finale en fonction d'une mesure précise. Par exemple on utilise souvent l'erreur au carré (*squared error*) ou la précision (*accuracy*) du modèle. \n",
    "\n",
    "N'oubliez pas que la terminologie ci-haut ne définit pas directement le modèle à utiliser, elle ne définit pas non plus la procédure pour estimer les paramètres.\n",
    "\n",
    "Notre problème de prédictions de notes (*ratings*) se décompose comme ceci: \n",
    "- Tâche: Notre tâche est de prédire les notes des utilisateurs pour les films. Nous pourrions la modéliser de différentes manières (plus de détails à la semaine 11), pour l'instant nous imaginons que c'est un problème de régression. \n",
    "- Expérience: L'expérience en est une d'apprentissage supervisé puisque nous essayons de prédire la note (la variable dépendante) à partir d'un ensemble de variables indépendantes.\n",
    "- La mesure de performance: Comme c'est souvent le cas en régression linéaire, nous utiliserons l'erreur moyenne au carrée.\n",
    "\n",
    "### Prétraitement des données\n",
    "\n",
    "Pour l'apprentissage supervisé, comme c'est souvent le cas, nous représenterons les données en utilisant deux matrices $X$ et $Y$. La première, $X$, contient les attributs (*features*). C'est une matrice de taille $n \\times p$, avec $n$ le nombre d'exemples et $p$ la dimensionnalité de chaque exemple (en d'autres mots, le nombre d'attributs de chaque exemple). \n",
    "\n",
    "$$X = \\begin{bmatrix} \n",
    "x_{11} & x_{12} & \\ldots & x_{1p} \\\\\n",
    "\\vdots & \\vdots       &  \\ddots      & \\vdots \\\\ \n",
    "x_{n1} & x_{12} & \\ldots & x_{np} \\\\\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "$Y$, est un vecteur (colonne) de taille $n$ qui content les étiquettes (ici ce sont les notes des films). $Y_1$ correspond aux notes de $X_1$.\n",
    "\n",
    "$$\n",
    "Y = \\begin{bmatrix} \n",
    "r_1 \\\\\n",
    "r_2 \\\\\n",
    "\\vdots \\\\ \n",
    "r_n\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Nous différencierons les ensembles d'entraînement (`train`) des ensembles de test (`test`), p.ex.,, en utilisant cette notation $X_\\text{train}$ et $X_\\text{test}$. Idem pour les étiquettes $Y_\\text{train}$ et $Y_\\text{test}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On commence\n",
    "\n",
    "Après cette courte introduction, nous pouvons maintenant nous pencher sur le problème et le code pour le résoudre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '80-629'...\n",
      "remote: Enumerating objects: 170, done.\u001b[K\n",
      "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
      "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
      "remote: Total 222 (delta 95), reused 126 (delta 51), pack-reused 52\u001b[K\n",
      "Receiving objects: 100% (222/222), 74.20 MiB | 4.48 MiB/s, done.\n",
      "Resolving deltas: 100% (109/109), done.\n"
     ]
    }
   ],
   "source": [
    "# Commencons par télécharger le code et les données (Ces étapes sont essentielles pour la plateforme colab)\n",
    "!rm -rf 80-629/\n",
    "!git clone https://github.com/lcharlin/80-629/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous importerons tout d'abord différentes libraires dont nous aurons besoin: \n",
    "- `reduce` une fonction qui sera pratique pour traiter des données de manière itérative\n",
    "- `os` une librairie standard pour, notamment, interagir avec le système de fichiers (p.ex., pour ouvrir un fichier)\n",
    "- `re` une librairie pour les expressions régulières\n",
    "- `sys` une librairie pour obtenir des informations du système \n",
    "- `time` une librairie pour évaluer le temps de calcul de certaines opérations (p.ex., estimer les paramètres d'un modèle)\n",
    "\n",
    "\n",
    "\n",
    "- `matplotlib` pour tracer des graphiques\n",
    "- `numpy` pour des fonctions d'algèbre linéaire\n",
    "- `pandas` pour manipuler les données\n",
    "- `sklearn` (scikit-learn) pour des modèles d'apprentissage automatique ainsi que des fonctions reliées à la pratique de l'apprentissage automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "import re \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neural_network\n",
    "\n",
    "import sys\n",
    "sys.path += ['80-629/week4-PracticalSession/']\n",
    "from local_utils import DrawNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pre-processing'></a>\n",
    "# Section 1: Prétraitement des données\n",
    "\n",
    "Dans les prochaines cellules, nous chargerons des données à partir d'un fichier csv et les prétraiterons. \n",
    "\n",
    "Bien que ce ne soit pas de l'apprentissage automatique, nos modèles auront toujours besoin de données. Il est donc utile de connaître quelques manières de traiter les données. (Notez qu'en pratique, il est souvent plus long de prétraiter les données que d'estimer les modèles.) \n",
    "\n",
    "**Je vous suggère de lire cette section, mais de plutôt vous attarder sur les sections subséquentes. Si vous finissez le tutoriel avant la fin de la séance, vous pourrez vous attarder sur cette section.** \n",
    "\n",
    "#### Quelques précisions\n",
    "\n",
    "Nous utiliserons le jeu de [données movielens](https://grouplens.org/datasets/movielens/) qui est disponible publiquement. Le groupe de recherche qui a récolté movielens, a récolté plusieurs jeux de données depuis 20 ans. Nous utiliserons surtout le jeu [ML-1M](https://grouplens.org/datasets/movielens/1m/) qui contient un million de notes. Nous utiliserons en plus les *tags* venant du [jeu ML-20M](https://grouplens.org/datasets/movielens/20m/) (celui-là contient 20M de notes). \n",
    "\n",
    "A part avoir téléchargé le jeu de données, je ne l'ai pas prétraité ou modifié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR='80-629/'\n",
    "DATA_DIR=os.path.join(ROOT_DIR, 'dat/ml-1m/') # C'est ici que se trouve les notes \n",
    "DATA_DIR_20ML=os.path.join(ROOT_DIR, 'dat/ml-20m/') # C'est ici que se trouve les *tags*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charger les noms et types des films\n",
    "\n",
    "Nous commençons par charger en mémoire les données qui décrivent les films du jeu ML-1M à partir du fichier `movies.data`. Chaque ligne dans ce fichier contient les informations suivantes `MovieID::Name::Genres`. \n",
    "\n",
    "Après avoir chargé les données dans une structure `dataFrame` de pandas, cette structure (movies_pd) contiendra les noms des films (`mName`), un identificateur unique (`mid`) et que la catégorie du film (`mGenres`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_pd = pd.read_csv(os.path.join(DATA_DIR, 'movies.dat'), \n",
    "                        sep='::', \n",
    "                        names=['mid', 'mName', 'mGenres'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce jeu de données contient 3883 films.\n"
     ]
    }
   ],
   "source": [
    "print(f'Ce jeu de données contient {movies_pd.shape[0]} films.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>mName</th>\n",
       "      <th>mGenres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                               mName                       mGenres\n",
       "0    1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1    2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2    3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3    4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4    5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(movies_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grace à pandas nous pouvons aussi chercher un film par son identificateur unique `mid` ainsi que par son nom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>mName</th>\n",
       "      <th>mGenres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid             mName                    mGenres\n",
       "9   10  GoldenEye (1995)  Action|Adventure|Thriller"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>mName</th>\n",
       "      <th>mGenres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1433</td>\n",
       "      <td>Machine, The (1994)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mid                mName        mGenres\n",
       "1409  1433  Machine, The (1994)  Comedy|Horror"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mid = 10  # cherchons le film avec l'identificateur 10\n",
    "display(movies_pd[movies_pd.mid==mid])\n",
    "\n",
    "name = 'Machine' # cherchons un film contenant ce mot dans son titre\n",
    "display(movies_pd[movies_pd.mName.str.contains(name, \n",
    "                                               regex=False, case=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charger les notes\n",
    "\n",
    "En utilisant la même fonction que plus haut, nous pouvons aussi charger les notes des utilisateurs pour les films. Elles sont dans ce format `UserID::MovieID::Rating::Timestamp` et nous nommerons la colonne avec l'identifiant de l'utilisateur `uid`, la colonne avec l'identifiant du film `mid`, la note avec `rating`, et le moment où la note a été ajoutée au système avec `timestamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   mid  rating  timestamp\n",
       "0    1  1193       5  978300760\n",
       "1    1   661       3  978302109\n",
       "2    1   914       3  978301968\n",
       "3    1  3408       4  978300275\n",
       "4    1  2355       5  978824291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_pd = pd.read_csv(os.path.join(DATA_DIR, 'ratings.dat'), \n",
    "                         sep='::',\n",
    "                         names=['uid', 'mid', 'rating', 'timestamp'],\n",
    "                         parse_dates=['timestamp'],\n",
    "                         infer_datetime_format=True,\n",
    "                         engine='python')\n",
    "\n",
    "display(ratings_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce jeu de données contient 1000209 notes, \n",
      "      venant de 6040 utilisateurs, \n",
      "      et de 3706 items (films).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Ce jeu de données contient {ratings_pd.shape[0]} notes, \n",
    "      venant de {ratings_pd.uid.nunique()} utilisateurs, \n",
    "      et de {ratings_pd.mid.nunique()} items (films).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charger les données sociodémographiques des utilisateurs\n",
    "\n",
    "Le fichier est aussi un csv en format `UserID::Gender::Age::Occupation::Zip-code`, que nous chargerons dans un `dataFrame` ayant les colonnes `uid,gender,age,occupation,zip`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid gender  age  occupation    zip\n",
       "0    1      F    1          10  48067\n",
       "1    2      M   56          16  70072\n",
       "2    3      M   25          15  55117\n",
       "3    4      M   45           7  02460\n",
       "4    5      M   25          20  55455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_pd = pd.read_csv(os.path.join(DATA_DIR, 'users.dat'),\n",
    "                       sep='::',\n",
    "                       names=['uid', 'gender', 'age', 'occupation', 'zip'],\n",
    "                       engine=\"python\")\n",
    "\n",
    "display(users_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce jeu de données contient 6040 utilisateurs.\n"
     ]
    }
   ],
   "source": [
    "print(f'Ce jeu de données contient {users_pd.shape[0]} utilisateurs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez peut-être remarqué que chaque code postal (zip code) est une suite de 5 chiffres. Puisqu'il y en a beaucoup, nous préférons les tronquer et en garder que les deux premiers chiffres (donc 27392 -> 27). La raison est simple, les codes postaux sont des variables catégorielles et nous n'avons que 6K utilisateurs et >3.4K codes postaux uniques, il est donc improbable que les coefficients qui y seront associés soient très précis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous débutons avec 3439 code postaux (zip codes) uniques.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    48\n",
       "1    70\n",
       "2    55\n",
       "3    02\n",
       "4    55\n",
       "Name: zip, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En ne conservant que les deux premiers chiffres de chaque code, nous réduisons le nombre de code uniques à 100.\n"
     ]
    }
   ],
   "source": [
    "print(f'Nous débutons avec {users_pd.zip.nunique()} code postaux (zip codes) uniques.')\n",
    "users_pd['zip'] = users_pd['zip'].apply(lambda x: x[:2])\n",
    "display(users_pd['zip'].head())\n",
    "print(f'En ne conservant que les deux premiers chiffres de chaque code, nous réduisons le nombre de code uniques à {users_pd.zip.nunique()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons aussi charger les *tags* associées aux films (nous utiliserons les *tags* du jeu de données ml-20M). Les utilisateurs associent les *tags* aux films. Chaque paire film-tag est aussi associée à un degré d'affinité (il dépend du nombre d'utilisateurs ayant *tagger* le film avec un *tag*). \n",
    "\n",
    "Encore une fois, nous chargerons les données csv `movieId,tagId,relevance` dans une structure `dataFrame` ayant les colonnes `mid,tid,relevance`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>tid</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.09675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.21700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.06700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.26275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.26200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.03200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid  tid  relevance\n",
       "0    1    1    0.02500\n",
       "1    1    2    0.02500\n",
       "2    1    3    0.05775\n",
       "3    1    4    0.09675\n",
       "4    1    5    0.14675\n",
       "5    1    6    0.21700\n",
       "6    1    7    0.06700\n",
       "7    1    8    0.26275\n",
       "8    1    9    0.26200\n",
       "9    1   10    0.03200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chargement des tags provenant du jeu ML-20m\n",
    "tags_scores = pd.read_csv(os.path.join(DATA_DIR_20ML, 'genome-scores.csv.gz'), \n",
    "                          skiprows=1, \n",
    "                          names=['mid', 'tid', 'relevance'])\n",
    "display(tags_scores.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données contiennent 1128 tags uniques.\n",
      "L'étendue des affinitées est de 0.00024999999999997247--1.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.170977e+07\n",
       "mean     1.164833e-01\n",
       "std      1.542463e-01\n",
       "min      2.500000e-04\n",
       "25%      2.425000e-02\n",
       "50%      5.650000e-02\n",
       "75%      1.415000e-01\n",
       "max      1.000000e+00\n",
       "Name: relevance, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Les données contiennent {tags_scores.tid.nunique()} tags uniques.')\n",
    "print(f\"L'étendue des affinitées est de {tags_scores.relevance.min()}--{tags_scores.relevance.max()}.\")\n",
    "display(tags_scores.relevance.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons que les affinitées sont donc (grosso modo) comprises entre des valeurs de 0 et de 1 avec une moyenne de 0.12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charger les noms des tags\n",
    "\n",
    "Ces données pourront être utiles pour mieux comprendre et explorer nos résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>tName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1950s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1960s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1970s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tid         tName\n",
       "0    1           007\n",
       "1    2  007 (series)\n",
       "2    3  18th century\n",
       "3    4         1920s\n",
       "4    5         1930s\n",
       "5    6         1950s\n",
       "6    7         1960s\n",
       "7    8         1970s\n",
       "8    9         1980s\n",
       "9   10  19th century"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_names = pd.read_csv(os.path.join(DATA_DIR_20ML, 'genome-tags.csv'), skiprows=1, names=['tid', 'tName'])\n",
    "display(tags_names.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque les tags viennent d'un autre ensemble de données qui est aussi plus récent (ml-20M), nous n'avons qu'à garder les tags qui correspondent à des films dans notre ensemble (ml-1M). Heureusement, puisque les deux jeux de données viennent du même fournisseur (movielens), les identifiants des films (`mid`) sont les mêmes dans les deux jeux de données (p.ex., nous n'avons donc pas besoin d'apparier les films selon leur titre, qui sont en général plus bruités).\n",
    "\n",
    "(Notez: Pandas vous donne accès à un ensemble d'opérations comparables aux fonctions de SQL pour les bases de données relationnelles.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3470\n"
     ]
    }
   ],
   "source": [
    "tags_scores = tags_scores.loc[tags_scores['mid'].isin(ratings_pd['mid'].unique())]\n",
    "print(tags_scores.mid.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons perdu quelques films (qui ne contenaient donc pas de *tags*), mais ce n'est pas très grave pour aujourd'hui.\n",
    "\n",
    "Ensuite, nous conserverons que les affinités les plus hautes pour chaque film. En d'autres mots, nous imaginons donc que la présence d'un *tag* est plus importante que son absence. En plus, cette opération nous permet de réduire le nombre de *tags* par film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique tags: 1128\n",
      "unique tags w. high relevance: 968\n"
     ]
    }
   ],
   "source": [
    "# Nous conversons que les pairs film-tag ayant une affinité supérieure à 0.9\n",
    "print('unique tags:', tags_scores['tid'].nunique())\n",
    "tags_scores_high = tags_scores.loc[tags_scores['relevance'] > 0.9]\n",
    "print('unique tags w. high relevance:', tags_scores_high['tid'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explorons les *tags*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de comprendre comment les utilisateurs du système ont *tagger* les films. Avant tout, il nous sera pratique d'avoir une structure de type `dataFrame` qui contiendra les noms de tags, les noms de films ainsi que les affinités.  (pour l'instant, ces données sont dans trois différentes structures). \n",
    "\n",
    "En pandas, la fonction `merge` est utile pour joindre deux `dataFrames` en utilisant une clé unique. (C'est une opération inspirée d'une jointure interne (*inner join*) en SQL.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>tid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>tName</th>\n",
       "      <th>mName</th>\n",
       "      <th>mGenres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.93325</td>\n",
       "      <td>animated</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.98575</td>\n",
       "      <td>animation</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>0.95650</td>\n",
       "      <td>cartoon</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>0.92625</td>\n",
       "      <td>childhood</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>0.96425</td>\n",
       "      <td>children</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid  tid  relevance      tName             mName  \\\n",
       "0    1   63    0.93325   animated  Toy Story (1995)   \n",
       "1    1   64    0.98575  animation  Toy Story (1995)   \n",
       "2    1  186    0.95650    cartoon  Toy Story (1995)   \n",
       "3    1  203    0.92625  childhood  Toy Story (1995)   \n",
       "4    1  204    0.96425   children  Toy Story (1995)   \n",
       "\n",
       "                       mGenres  \n",
       "0  Animation|Children's|Comedy  \n",
       "1  Animation|Children's|Comedy  \n",
       "2  Animation|Children's|Comedy  \n",
       "3  Animation|Children's|Comedy  \n",
       "4  Animation|Children's|Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_high_names_movies = pd.merge(tags_scores_high, tags_names, how='inner', on='tid')\n",
    "tags_high_names_movies = pd.merge(tags_high_names_movies, movies_pd, how='inner', on='mid')\n",
    "display(tags_high_names_movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un peu comme plus haut, nous pouvons maintenant trouver les films ayant la plus haute affinité pour une certaine *tag*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>tid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>tName</th>\n",
       "      <th>mName</th>\n",
       "      <th>mGenres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>2710</td>\n",
       "      <td>882</td>\n",
       "      <td>0.96700</td>\n",
       "      <td>scary</td>\n",
       "      <td>Blair Witch Project, The (1999)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14005</th>\n",
       "      <td>1342</td>\n",
       "      <td>882</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>scary</td>\n",
       "      <td>Candyman (1992)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9205</th>\n",
       "      <td>1347</td>\n",
       "      <td>882</td>\n",
       "      <td>0.96550</td>\n",
       "      <td>scary</td>\n",
       "      <td>Nightmare on Elm Street, A (1984)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14658</th>\n",
       "      <td>3892</td>\n",
       "      <td>882</td>\n",
       "      <td>0.96475</td>\n",
       "      <td>scary</td>\n",
       "      <td>Anatomy (Anatomie) (2000)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>1997</td>\n",
       "      <td>882</td>\n",
       "      <td>0.96200</td>\n",
       "      <td>scary</td>\n",
       "      <td>Exorcist, The (1973)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>2550</td>\n",
       "      <td>882</td>\n",
       "      <td>0.95625</td>\n",
       "      <td>scary</td>\n",
       "      <td>Haunting, The (1963)</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11492</th>\n",
       "      <td>1350</td>\n",
       "      <td>882</td>\n",
       "      <td>0.94675</td>\n",
       "      <td>scary</td>\n",
       "      <td>Omen, The (1976)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11546</th>\n",
       "      <td>2841</td>\n",
       "      <td>882</td>\n",
       "      <td>0.94650</td>\n",
       "      <td>scary</td>\n",
       "      <td>Stir of Echoes (1999)</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>1974</td>\n",
       "      <td>882</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>scary</td>\n",
       "      <td>Friday the 13th (1980)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>1387</td>\n",
       "      <td>882</td>\n",
       "      <td>0.94250</td>\n",
       "      <td>scary</td>\n",
       "      <td>Jaws (1975)</td>\n",
       "      <td>Action|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>2460</td>\n",
       "      <td>882</td>\n",
       "      <td>0.93925</td>\n",
       "      <td>scary</td>\n",
       "      <td>Texas Chainsaw Massacre 2, The (1986)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>1214</td>\n",
       "      <td>882</td>\n",
       "      <td>0.93875</td>\n",
       "      <td>scary</td>\n",
       "      <td>Alien (1979)</td>\n",
       "      <td>Action|Horror|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>3273</td>\n",
       "      <td>882</td>\n",
       "      <td>0.93825</td>\n",
       "      <td>scary</td>\n",
       "      <td>Scream 3 (2000)</td>\n",
       "      <td>Horror|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13208</th>\n",
       "      <td>1590</td>\n",
       "      <td>882</td>\n",
       "      <td>0.93525</td>\n",
       "      <td>scary</td>\n",
       "      <td>Event Horizon (1997)</td>\n",
       "      <td>Action|Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13916</th>\n",
       "      <td>1321</td>\n",
       "      <td>882</td>\n",
       "      <td>0.93475</td>\n",
       "      <td>scary</td>\n",
       "      <td>American Werewolf in London, An (1981)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>2160</td>\n",
       "      <td>882</td>\n",
       "      <td>0.93325</td>\n",
       "      <td>scary</td>\n",
       "      <td>Rosemary's Baby (1968)</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>2719</td>\n",
       "      <td>882</td>\n",
       "      <td>0.92450</td>\n",
       "      <td>scary</td>\n",
       "      <td>Haunting, The (1999)</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>3499</td>\n",
       "      <td>882</td>\n",
       "      <td>0.92350</td>\n",
       "      <td>scary</td>\n",
       "      <td>Misery (1990)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>2762</td>\n",
       "      <td>882</td>\n",
       "      <td>0.92075</td>\n",
       "      <td>scary</td>\n",
       "      <td>Sixth Sense, The (1999)</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>1258</td>\n",
       "      <td>882</td>\n",
       "      <td>0.91675</td>\n",
       "      <td>scary</td>\n",
       "      <td>Shining, The (1980)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12355</th>\n",
       "      <td>3081</td>\n",
       "      <td>882</td>\n",
       "      <td>0.91425</td>\n",
       "      <td>scary</td>\n",
       "      <td>Sleepy Hollow (1999)</td>\n",
       "      <td>Horror|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>1200</td>\n",
       "      <td>882</td>\n",
       "      <td>0.90475</td>\n",
       "      <td>scary</td>\n",
       "      <td>Aliens (1986)</td>\n",
       "      <td>Action|Sci-Fi|Thriller|War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mid  tid  relevance  tName                                   mName  \\\n",
       "13151  2710  882    0.96700  scary         Blair Witch Project, The (1999)   \n",
       "14005  1342  882    0.96625  scary                         Candyman (1992)   \n",
       "9205   1347  882    0.96550  scary       Nightmare on Elm Street, A (1984)   \n",
       "14658  3892  882    0.96475  scary               Anatomy (Anatomie) (2000)   \n",
       "3187   1997  882    0.96200  scary                    Exorcist, The (1973)   \n",
       "14021  2550  882    0.95625  scary                    Haunting, The (1963)   \n",
       "11492  1350  882    0.94675  scary                        Omen, The (1976)   \n",
       "11546  2841  882    0.94650  scary                   Stir of Echoes (1999)   \n",
       "9340   1974  882    0.94625  scary                  Friday the 13th (1980)   \n",
       "2976   1387  882    0.94250  scary                             Jaws (1975)   \n",
       "5121   2460  882    0.93925  scary   Texas Chainsaw Massacre 2, The (1986)   \n",
       "2488   1214  882    0.93875  scary                            Alien (1979)   \n",
       "9478   3273  882    0.93825  scary                         Scream 3 (2000)   \n",
       "13208  1590  882    0.93525  scary                    Event Horizon (1997)   \n",
       "13916  1321  882    0.93475  scary  American Werewolf in London, An (1981)   \n",
       "11518  2160  882    0.93325  scary                  Rosemary's Baby (1968)   \n",
       "4825   2719  882    0.92450  scary                    Haunting, The (1999)   \n",
       "7636   3499  882    0.92350  scary                           Misery (1990)   \n",
       "3452   2762  882    0.92075  scary                 Sixth Sense, The (1999)   \n",
       "2781   1258  882    0.91675  scary                     Shining, The (1980)   \n",
       "12355  3081  882    0.91425  scary                    Sleepy Hollow (1999)   \n",
       "2343   1200  882    0.90475  scary                           Aliens (1986)   \n",
       "\n",
       "                              mGenres  \n",
       "13151                          Horror  \n",
       "14005                          Horror  \n",
       "9205                           Horror  \n",
       "14658                          Horror  \n",
       "3187                           Horror  \n",
       "14021                 Horror|Thriller  \n",
       "11492                          Horror  \n",
       "11546                        Thriller  \n",
       "9340                           Horror  \n",
       "2976                    Action|Horror  \n",
       "5121                           Horror  \n",
       "2488    Action|Horror|Sci-Fi|Thriller  \n",
       "9478          Horror|Mystery|Thriller  \n",
       "13208  Action|Mystery|Sci-Fi|Thriller  \n",
       "13916                          Horror  \n",
       "11518                 Horror|Thriller  \n",
       "4825                  Horror|Thriller  \n",
       "7636                           Horror  \n",
       "3452                         Thriller  \n",
       "2781                           Horror  \n",
       "12355                  Horror|Romance  \n",
       "2343       Action|Sci-Fi|Thriller|War  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tag = 'scary' # Le nom (partiel ou complet) du tag que nous chercherons\n",
    "display(tags_high_names_movies[\n",
    "    tags_high_names_movies.tName.str.contains(tag, \n",
    "                                               regex=False, case=False)].sort_values(by=['relevance'],\n",
    "                                                                                    ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette prochaine étape nous permettra d'explorer de manière plus complète les *tags* en plus de fournir un prétraitement qui sera utile pour estimer les modèles à partir de ces données.\n",
    "\n",
    "Dans le jeu de données actuel, chaque pair film-tag est dans un exemple différent (c.-à-d. dans une différente rangée du `dataFrame`). Il sera essentiel pour les modèles que tous les attributs d'un exemple soient sur une même ligne. Nous voulons donc construire une matrice $X$ où chaque exemple aura sa propre ligne. \n",
    "\n",
    "Pour ce faire, nous allons réencoder les `tid` en utilisant un encodage 1-de-K aussi connu comme l'ajout de variables *dummy*. Il est essentiel de comprendre que les données catégorielles (par exemple, « chien / chat ») ne sont pas des variables numériques comme les autres **puisqu'elles n'ont pas d'ordre**. Dans notre jeu de données, les tags ont une valeur numérique (p.ex., la *tag* `scary` a la valeur `882`), mais on ne peut pas comparer les *tags* à l'aide de cette valeur (p.ex., on ne peut pas dire que la *tag* `882` est plus grande que la *tag* `880` ou plus petite que la *tag* `900`). L'encodage 1-de-K traite ce cas en encodant chaque *tag* dans un vecteur binaire, de taille $K$ où la seule valeur non nulle (en général avec une valeur de 1) correspond à l'index du tag. Dans le cas présent, nous avons $K=968$ *tags*, et la *tag* `scary` serait encodée dans un vecteur de `0` ayant une seul `1` à la position `882`. \n",
    "\n",
    "Ci-bas vous verrez qu'après cette transformation (1-de-K), nos données ont maintenant 971 colonnes: 968 pour les tags, une pour le `mid`, une pour la note (`relevance`) et une dernière pour l'index de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>tid_1</th>\n",
       "      <th>tid_2</th>\n",
       "      <th>tid_3</th>\n",
       "      <th>tid_5</th>\n",
       "      <th>tid_6</th>\n",
       "      <th>tid_7</th>\n",
       "      <th>tid_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tid_1119</th>\n",
       "      <th>tid_1120</th>\n",
       "      <th>tid_1121</th>\n",
       "      <th>tid_1122</th>\n",
       "      <th>tid_1123</th>\n",
       "      <th>tid_1124</th>\n",
       "      <th>tid_1125</th>\n",
       "      <th>tid_1126</th>\n",
       "      <th>tid_1127</th>\n",
       "      <th>tid_1128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 971 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  mid  relevance  tid_1  tid_2  tid_3  tid_5  tid_6  tid_7  tid_9  \\\n",
       "0     62    1    0.93325      0      0      0      0      0      0      0   \n",
       "1     63    1    0.98575      0      0      0      0      0      0      0   \n",
       "2    185    1    0.95650      0      0      0      0      0      0      0   \n",
       "3    202    1    0.92625      0      0      0      0      0      0      0   \n",
       "4    203    1    0.96425      0      0      0      0      0      0      0   \n",
       "\n",
       "   ...  tid_1119  tid_1120  tid_1121  tid_1122  tid_1123  tid_1124  tid_1125  \\\n",
       "0  ...         0         0         0         0         0         0         0   \n",
       "1  ...         0         0         0         0         0         0         0   \n",
       "2  ...         0         0         0         0         0         0         0   \n",
       "3  ...         0         0         0         0         0         0         0   \n",
       "4  ...         0         0         0         0         0         0         0   \n",
       "\n",
       "   tid_1126  tid_1127  tid_1128  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 971 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(tags_scores_high.shape)\n",
    "tags_scores_high_dum = pd.get_dummies(tags_scores_high, columns=['tid'])\n",
    "tags_scores_high_dum = tags_scores_high_dum.reset_index()\n",
    "#print(tags_scores_high_dum.shape)\n",
    "display(tags_scores_high_dum.head())\n",
    "tags_per_movie = tags_scores_high_dum.groupby(\"mid\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à ces données, nous pouvons aisément explorer la distribution du nombre de films par tag (et inversement du nombre de tags par film, voir dessous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th = tags_scores_high.groupby(\"tid\").count()\n",
    "hists = th.hist(bins=50, column=\"mid\", xlabelsize=15, ylabelsize=15)[0][0]\n",
    "hists.set_ylabel(\"Tags\", size=15)\n",
    "hists.set_xlabel(\"Films par tag\", size=15)\n",
    "hists.set_title(\"Histogramme des films par tag\", size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet histogramme chaque barre verticale correspond au nombre de *tags* (axe des y) pour un nombre de films (axe des x). Par exemple, il y a 350 *tags* n'ont été utilisé qu'une poignée de fois (<5). La *tag* la plus populaire a été associée à 210 films.\n",
    "\n",
    "La distribution est asymétrique à gauche ce qui indique que la majorité des tags n'ont été associées qu'à un petit nombre de films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tag la plus populaire \"comedy\" a été associée à 210 films.\n"
     ]
    }
   ],
   "source": [
    "tname = tags_names.at[tags_names.tid.eq(th.mid.idxmax()).idxmax(), 'tName']\n",
    "print(f'La tag la plus populaire \"{tname}\" a été associée à {th.mid.max()} films.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la même idée (et presque le même code), nous pouvons obtenir quelque chose de similaire pour les films (plutôt que les *tags*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hists = tags_scores_high.groupby(\"mid\").count().hist(bins=40, column=\"tid\", xlabelsize=15, ylabelsize=15)\n",
    "hists[0][0].set_ylabel(\"Films\", size=15)\n",
    "hists[0][0].set_xlabel(\"Tags par film\", size=15)\n",
    "hists[0][0].set_title(\"Histogramme des tags par films\", size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur cet histogramme chaque barre verticale indique le nombre de films (y-axis) associé à un nombre de *tags*. Par exemple, il y a un peu moins de 500 films qui ont reçu une seule 1 *tag*. Un film en a reçu presque 40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:**\n",
    "Quel est le film ayant reçu le plus de *tags* (celui avec prêt de 40)? Bonus: pouvez-vous trouver les 5 films ayant reçu le plus de tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse:** Ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bf3fde8c6491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags_scores_high\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovies_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Le film le plus populaire est \"{mname.to}\" et il a {mh.tid.max()} tags.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "mh = tags_scores_high.groupby(\"mid\").count()\n",
    "mname = movies_pd.loc[movies_pd['mid'] == mh.tid.idxmax()].mName.to_string()\n",
    "print(f'Le film le plus populaire est \"{mname.to}\" et il a {mh.tid.max()} tags.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les prochaines étapes créent un ensemble de données pour l'apprentissage supervisé. Rappelons-nous que nous voulons arriver à prédire les notes que des utilisateurs donneraient à un film à partir de l'utilisateur, du film, ainsi que des attributs des deux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joindre les utilisateurs, les notes et les tags.\n",
    "data_pd = pd.merge(users_pd, ratings_pd, how='inner', on='uid')\n",
    "data_pd = pd.merge(data_pd, tags_per_movie, how='inner', on='mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce tutoriel, nous utiliserons qu'une fraction des données disponibles pour s'assurer que nous puissions estimer les modèles rapidement (en quelques minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on mélange les données et l'on garde 2% de toutes les notes\n",
    "# (nous n'utilisons qu'un petit sous ensemble des données pour des raisons computationelles)\n",
    "data_pd = data_pd.sample(frac=0.02, random_state=1234)\n",
    "print(data_pd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données final à la taille suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Statistiques descriptives de notre jeu de donées.')\n",
    "print('\\t- %d films'   % data_pd['mid'].nunique())\n",
    "print('\\t- %d utilisateurs'   % data_pd['uid'].nunique())\n",
    "print('\\t- %d notes' % data_pd.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note que nous avons plusieurs variables catégorielles (p.ex., sexe, l'emploi, le zip, mid). Comme dans le cas des *tags* nous encoderons ces catégorielles avec des variables dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_pd.shape)\n",
    "display(data_pd[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['gender','occupation','zip','mid','uid']\n",
    "data_pd_dum = pd.get_dummies(data_pd, columns=cols)\n",
    "print(data_pd_dum.shape)\n",
    "display(data_pd_dum.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi d'utiliser pandas pour transformer les variables catégorielles, nous aurions aussi pu utiliser `scikit-learn`. Le module `preprocessing` est introduit ici [here](https://scikit-learn.org/stable/modules/preprocessing.html). Je vous conseille la section sur les [Categorical features](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes prêts (finalement!) pour construire notre premier jeu de données complet. Pour démarrer, nous utiliserons qu'un sous ensemble des attributs disponibles et notamment nous n'utiliserons pas les *tags*. \n",
    "\n",
    "Ci-dessous, nous allons aussi séparer notre jeu de données en un ensemble d'entraînement et un de test en utilisant la fonction `train_test_split` de `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = \"mid_*|uid_*|gender_*|age|zip_*|occupation_*\"\n",
    "X = data_pd_dum.filter(regex=('('+attributes+')')) \n",
    "print(X.shape)\n",
    "\n",
    "rating = data_pd_dum['rating']\n",
    "print(rating.shape)\n",
    "\n",
    "# Diviser en Train/Test\n",
    "# On garde 20% des données pour l'ensemble de test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, rating, test_size=0.2, random_state=1234, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Particularité des systèmes de recommandations:* nous avons divisé les données sans égard aux utilisateurs et aux items. En d'autres mots, les utilisateurs les plus actifs ainsi que les films les plus populaires (en moyenne) seront plus représentés dans les données non observées. Ce n'est pas nécessairement un problème, mais nous pourrions désirer être plus équitables. Dans ce cas, on pourrait diviser indépendamment les données de chaque utilisateur, et s'assurer par exemple que l'ensemble non observé contient le même nombre de données pour chaque utilisateur (ou chaque film).\n",
    "\n",
    "*Particularité des systèmes de recommandations #2:* dans un cas réel, il aurait sans doute été souhaitable de diviser les notes en fonction du temps. Les notes avant une date précise pour l'ensemble d'entraînement et les autres pour l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modelling\"></a>\n",
    "# Section 2: Modélisation \n",
    "\n",
    "Les notes ou *ratings* ([échelle de Likert](https://fr.wikipedia.org/wiki/%C3%89chelle_de_Likert)) sont des quantités ordinales. Par contre, pour faciliter la modélisation, nous les traiterons comme des valeurs réelles (nous discuterons de ces questions à la semaine 11). Nous mesurerons donc l'erreur (la fonction de perte) carrée moyenne:\n",
    "\n",
    "$$ \\text{MSE}(f(x),y) := \\frac{1}{n} \\sum_{i=0}^n (f(x_i) - y_i)^2$$ \n",
    "\n",
    "La MSE est la distance moyenne entre la prédiction ($f(x_i)$) et l'étiquette ($y_i$). La fonction MSE retourne une quantité non négative et le modèle parfait a une MSE de $0$. Si le Modèle #1 a une plus petite MSE que le Modèle #2, alors le Modèle 1 est meilleur selon cette mesure.\n",
    "\n",
    "*Entraînement/Test:* rappelez vous que bien que nous estimions les paramètres du modèle à partir de l'ensemble **d'entraînement**, nous évaluons la qualité du modèle à partir des données de **test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Un premier modèle: prédire la moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est souvent pratique d'obtenir un point de comparaison en utilisant une méthode très simple. \n",
    "\n",
    "Notre méthode étalon sera un modèle qui prédit la moyenne des notes d'entraînements. C'est donc un modèle constant qui ne prend pas en compte les attributs (des utilisateurs ou des films): \n",
    "\n",
    "$$ \n",
    "y_{ui} = \\text{moyenne globale}\n",
    "$$\n",
    "\n",
    "*Particularité des systèmes de recommandations:* nous pourrions sand doute obtenir un modèle un peu plus performant en prédisant, pour chaque utilisateur la moyenne de ses notes (ou de manière équivalente pour les items) plutôt que la moyenne globale des notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantifier l'erreur de prédiction du modèle étalon\n",
    "\n",
    "print(\"Modèle constant\")\n",
    "\n",
    "print(\"\\tErreur carrée moyenne d'entraînement: %.3f\"\n",
    "      % mean_squared_error(y_train, \n",
    "                           np.full_like(y_train, y_train.mean())))\n",
    "print(\"\\tErreur carrée moyenne de test: %.3f\"\n",
    "      % mean_squared_error(y_test, \n",
    "                           np.full_like(y_test, y_train.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les erreurs d'entraînement et de test sont, dans ce cas, très proches (la différence n'est peut-être pas significative statistiquement). Notre modèle est très simple (en apprentissage automatique on dirait qu'il a sans doute un biais élevé) et on n'imaginerait donc pas que sa performance fluctue énormément d'un ensemble de test à un autre (petite variance).\n",
    "\n",
    "Cette erreur de test indique qu'en moyenne nos prédictions sont à 1.3 unité ($sqrt{1.6}$) de la véritable note. Ça indique donc que nous ne devrions pas être trop surpris que le modèle prédise une note sous 4 pour un film que nous aurions noté comme un 5. Cela dit, cette valeur reste quelque peu abstraite (est-ce un bon modèle ou non?) au moins jusqu'à ce qu'on la compare à la performance d'autres modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Régression Linéaire\n",
    "\n",
    "Pour ce second modèle, nous utiliserons un modèle de régression linéaire des notes à partir des attributs des utilisateurs. Nous utiliserons le sexe des utilisateurs, leur âge, leur code postal et leur emploi. Nous estimons ce modèle\n",
    "$$\n",
    "f(x_{ui}) = \\theta_\\text{gender} x_{\\text{gender}_u} + \\theta_{\\text{age}} x_{\\text{age}_u} + \\theta_\\text{zip} x_{\\text{zip}_u} + \\theta_\\text{occupation} x_{\\text{occupation}_u} + \\theta_\\text{uid} x_{\\text{uid}_u} + \\theta_{\\text{mid}} x_{\\text{mid}_i}\n",
    "$$ \n",
    "\n",
    "$\\theta_{1:6}$ sont les paramètres, $\\text{gender}_u$ est le sexe de l'utilisateur $u$, nous utilisons une notation similaire pour les autres attributs. Aussi, $x_{\\text{uid}_u}$ est l'identité de l'utilisateur, c'est similaire pour $x_{\\text{mid}_i}$ et les films.\n",
    "\n",
    "Veuillez noter que quelques-unes de ces variables sont catégorielles alors elles sont en fait encodées par un vecteur de paramètres. Par exemple, zip est une variable catégorielle avec 100 valeurs possibles, donc $\\theta_{\\text{zip}}$ a 100 dimensions. \n",
    "\n",
    "Pour entrainer le modèle, il faut minimiser l'erreur d'entrainement (train MSE), c'est exactement ce que propose la classe `LinearRegression`. (C'est un problème de [moindre carrés](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html) et il existe donc une solution en forme fermée.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer l'objet de régression linéaire\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner le modèle à partir des données d'entraiînement\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Number of parameters: \", reg.coef_.shape[0]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de regarder les résultats. Pensez-vous que le modèle que nous venons d'entraîner généralisera bien ou non? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions d'entraînement\n",
    "y_train_pred = reg.predict(X_train)\n",
    "\n",
    "print(\"Erreur carrée moyenne d'entraînement: %.3f\"\n",
    "      % mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Obtenir les prédictions de test\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Erreur carrée moyenne de test: %.3f\"\n",
    "      % mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que l'erreur d'entraînement est $<<$ que l'erreur de test ($<<$ veut dire « bien plus petit »). C'est évidemment un problème de surentraînement (*overfitting*). C'est-à-dire que le modèle a appris l'ensemble d'entraînement et ne peut donc pas généraliser à de nouvelles données (c'est un modèle à faible biais et variance élevée). \n",
    "\n",
    "Comme nous en avons discuté en classe, il existe plusieurs méthodes pour limiter voir empêcher le surentraînement. Pour l'instant, nous régulariserons le modèle pour limiter le surentraînement. L'idée est que nous ajouterons à la fonction de perte un terme pour empêcher les paramètres de prendre des valeurs trop élevées, ce qui à priori, devrait aider le modèle à mieux généraliser (notamment parce que la fonction sera plus lisse). Cette pénalité ou régularisateur est ajouter à la fonction de perte qui devient:s\n",
    "$$  \\text{loss} := \\text{MSE} + \\alpha \\sum_i ||\\theta_i||_2^2 $$\n",
    "\n",
    "Au lieu de $ \\text{loss} := \\text{MSE} $. Notez: \n",
    "- $||\\cdot||_2$ est la norme 2. C'est-à-dire la racine carrée de la somme des éléments au carré.\n",
    "- $\\alpha$ est un hyperparamètre qui fixe l'importance du régularisateur (si $\\alpha=0$ la régularisateur est nul et si $\\alpha=\\infty$ tous les paramètres régularisés doivent être exactement égales à 0). Un hyperparamètre n'est pas appris pendant l'entraînement, mais fixé à priori (ici, apprendre $\\alpha$ en même temps que $\\theta$ mènerait à estimer $\\alpha=0$). \\[Dans les notes de cours, j'ai utilisé le symbole $\\lambda$ pour cet hyperparamètre.\\]\n",
    "\n",
    "Pendant l'entraînement, le modèle doit trouver un compromis entre la performance (MSE) et la complexité du modèle ($\\theta$ élevés). \n",
    "\n",
    "Notez, qu'il y a différents noms pour ce régularisateur par exemple *weight decay*, *L2-regularization* et régression *ridge*. Scikit-learn utilise la classe `Ridge` dans la libraire `linear_model` pour estimer un modèle de régression linéaire régularisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle de régression linéaire régularisé\n",
    "regr = linear_model.Ridge(alpha=10)\n",
    "\n",
    "# Entraîner le modèle avec l'ensemble d'entraînement\n",
    "start = time.time()\n",
    "regr.fit(X_train, y_train)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "print(\"Temps d'apprentissage: %.2f seconds\" % fit_time)\n",
    "\n",
    "print(\"Nombre de paramètres:\", regr.coef_.shape[0]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Pourquoi le modèle a 7,184 paramètres? En d'autres mots, à quoi correspondent ces paramètres?\n",
    "\n",
    "**Indice:** N'oubliez pas le terme de biais (intercepte)\n",
    "\n",
    "**Réponse:** Il y a un intercepte et 7183 attributs: \n",
    "- 2 sexe, \n",
    "- 100 code postal,\n",
    "- 2403 mid, \n",
    "- 46562 uid,\n",
    "- 1 age, \n",
    "- 21 emploi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions sur l'ensemble d'entraînement\n",
    "y_train_pred = regr.predict(X_train)\n",
    "\n",
    "print(\"Erreur au carré moyenne d'entraînement: %.3f\"\n",
    "      % mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Obtenir les prédictions sur l'ensemble de test\n",
    "y_test_pred = regr.predict(X_test)\n",
    "\n",
    "print(\"Erreur au carré moyenne de test: %.3f\"\n",
    "      % mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par rapport au modèle sans régularisation, nous observons que le modèle avec $\\alpha=10$ obtient des erreurs  beaucoup plus proches l'une de l'autre (il y a donc moins de surentraînement). D'autres valeurs de $\\alpha$ devrait aussi affecter la capacité à généraliser du modèle.\n",
    "\n",
    "\n",
    "**Question 4:** Comment trouver la meilleure valeur pour $\\alpha$ étant donné un modèle et un jeu de données?\n",
    "\n",
    "**Indice:** Regardez [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV), une version du modèle ridge avec de la validation croisée.\n",
    "\n",
    "**Answer:** Voir plus bas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer l'objet de régression linéaire\n",
    "regRCV = linear_model.RidgeCV(alphas=[1, 10, 100])\n",
    "\n",
    "# Entraîner le modèle à partir de l'ensemble d'entraînement\n",
    "regRCV.fit(X_train, y_train)\n",
    "\n",
    "print(\"Nombre de paramètres: %d, estimated alpha: %d\" % (regRCV.coef_.shape[0], regRCV.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas $\\alpha=10$ offre la meilleure performance sur un ensemble (interne) de validation comparativement aux autres valeurs de $\\alpha$ proposées.\n",
    "\n",
    "Remarque technique: puisque l'estimation des paramètres est souvent effectuée en prenant une transformation logarithmique de l'objectif, il est normal d'essayer des valeurs de $\\alpha$ qui correspondent à des puissances de 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions d'entraînement\n",
    "y_train_pred = regRCV.predict(X_train)\n",
    "\n",
    "print(\"Erreur carrée moyenne d'entraînement: %.3f\"\n",
    "      % mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Obtenir les prédictions de test\n",
    "y_test_pred = regRCV.predict(X_test)\n",
    "\n",
    "print(\"Erreur carrée moyenne de test: %.3f\"\n",
    "      % mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'avantage de la validation croisée (par exemple `RidgeCV`) est clair. Cette méthode cherche automatiquement la meilleure valeur d'un hyper paramètre (ici $\\alpha$) à partir d'un ensemble possible (ici:  $\\{ 1, 10, 100 \\}$). \n",
    "\n",
    "La validation croisée devrait toujours être utilisée pour trouver de bons hyper paramètres (surtout pour les modèles non linéaires, différents hyper paramètres peuvent donner des résultats bien différents). Il est aussi possible que vous deviez implémenter cette procédure vous-même. Dans ce cas, il est alors nécessaire d'utiliser (explicitement) un ensemble de validation (que vous diviser à partir de votre ensemble d'entraînement). Dans `sklearn` vous pouvez utiliser la fonction `train_test_split`. La taille de l'ensemble de validation est souvent la même que la taille de l'ensemble de test.\n",
    "\n",
    "Très important, **ne sélectionnez jamais vos hyperparamèetres en fonction de votre performance sur l'ensemble de test**, ceci vous donnera des résultats trop optimistes (donc une erreur plus basse) puisque vous utilisez en fait votre ensemble de test pour entraîner votre modèle. L'ensemble de test sert à obtenir une estimation non biaisée de l'erreur qui peut donc être utilisée pour comparer différents modèles. \n",
    "\n",
    "***\n",
    "\n",
    "Maintenant que nous avons un modèle entraîné, nous pouvons explorer ses prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpfer function to return non-zero columns\n",
    "def non_zero(row, columns):\n",
    "    col_name = list(columns[~(row == 0)])[0]\n",
    "    #r = re.sub('mid_','',l)\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenir le nombre de notes par film (popularité)\n",
    "mids = X_test.filter(regex=('mid_*'))\n",
    "y_mid_cols = mids.apply(lambda x: non_zero(x, mids.columns), axis=1)\n",
    "movie_popularity = X_train.filter(regex=('mid_*')).sum(axis=0)[ y_mid_cols ]\n",
    "\n",
    "# obtenir le nombre de notes par utilisateur (niveau d'activité d'un utilisateur)\n",
    "uids = X_test.filter(regex=('uid_*'))\n",
    "y_uid_cols = uids.apply(lambda x: non_zero(x, uids.columns), axis=1)\n",
    "user_activity = X_train.filter(regex=('uid_*')).sum(axis=0)[ y_uid_cols ]\n",
    "\n",
    "err = (y_test_pred-y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplement tracer un sous-ensemble pour l'interprétabilité\n",
    "subn = 500 \n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2)\n",
    "fig.set_figwidth(15)\n",
    "ax0.scatter(movie_popularity[:subn], err[:subn])\n",
    "ax0.set_ylabel('Prediction error')\n",
    "ax0.set_xlabel('Movie Popularity')\n",
    "\n",
    "ax1.scatter(user_activity[:subn], err[:subn])\n",
    "ax1.set_ylabel('Prediction error')\n",
    "ax1.set_xlabel('User Activity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux figures montrent l'erreur des prédictions (sur un sous-ensemble) de test versus la popularité des films (axe des x à gauche) et le niveau d'activité d'un utilisateur (axe des x à droite). Notez que:\n",
    "\n",
    "- Cette distribution empirique semble symétrique, donc il y n'y a pas de biais particulier à des prédictions plus élevées ou plus basses.\n",
    "- L'erreur de prédiction semble montrer que les films et les utilisateurs ayant plus de données ont aussi une plus petite erreur de prédiction (c.-à-d., les données forment un \"triangle\" pointant vers la droite, ceci devient beaucoup plus évident quand nous entraînons le modèle avec plus de données). Ce résultat tombe sous le sens, le plus de données le modèle observe sur un film, le plus précis le modèle devrait être pour ce film (son estimation de $\\theta_{\\text{mid}}$ sera plus précise). Cet effet est peut-être aussi renforcé par le fait que nous ayons divisé les données aléatoirement en entraînement et test. Il devient plus avantageux pour le modèle de correctement modéliser les films et les utilisateurs ayant le plus de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Régression linéaire avec les tags comme attribut.\n",
    "\n",
    "Nous utilisons encore une fois un modèle de régression linéaire, mais nous y ajoutons les tags des films:\n",
    "\n",
    "$$\n",
    "f(x_{ui}) = \\theta_\\text{gender} x_{\\text{gender}_u} + \\theta_{\\text{age}} x_{\\text{age}_u} + \\theta_\\text{zip} x_{\\text{zip}_u} + \\theta_\\text{occupation} x_{\\text{occupation}_u} + \\theta_\\text{uid} x_{\\text{uid}_u} + \\theta_{\\text{mid}} x_{\\text{mid}_i} \\mathbf{+ x_{\\text{tags}_i}\\boldsymbol\\theta_\\text{tags}}\n",
    "$$ \n",
    "\n",
    "Le dernier terme à droite (en gras) est ajouté par rapport au modèle précédent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Comment pensez-vous que ce modèle performera par rapport au modèle précédent (Section 2.2.)? Pouvez-vous dire quelque chose de formel par rapport à sa performance?\n",
    "\n",
    "**Indice:** Un des modèles est une généralisation de l'autre. \n",
    "\n",
    "**Réponse:** \n",
    "- Le modèle 2.2 est un cas particulier du modèle 2.3. Quand $\\theta_\\text{tags}=0$ les deux modèles sont équivalents. \n",
    "- Le modèle 2.3 pourrait donc atteindre une meilleure performance que le modèle 2.2. C'est aussi possible, que ces attributs en plus mènent à un modèle qui puisse plus facilement surentraîner. \n",
    "- Puisque le modèle 2.3 pourrait apprendre que $\\theta_\\text{tags}=0$, il ne devrait jamais performer moins bien que le modèle 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous construisons maintenant un jeu de données en y ajoutant les tags (tid_*)\n",
    "X_tags = data_pd_dum.filter(regex=('('+attributes+\"|tid_*\"+')'))\n",
    "print(X_tags.shape)\n",
    "\n",
    "# Divisons l'échantillon en Entraînement/Test.\n",
    "# Nous utilisons la machine racine (seed) qu'avant pour s'assurer que la division sera la même\n",
    "X_train_tags, X_test_tags, y_train_tags, y_test_tags = train_test_split(\n",
    "    X_tags, rating, test_size=0.2, random_state=1234, shuffle=False)\n",
    "print(X_train_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer l'oject de régression linéaire\n",
    "regr_tags = linear_model.Ridge(alpha=10)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "start = time.time()\n",
    "regr_tags.fit(X_train_tags, y_train_tags)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "print(\"Temps de l'apprentissage du modèle: %.2f seconds\" % fit_time)\n",
    "print(\"Nombre de paramètres:\", regr_tags.coef_.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions d'entraînement\n",
    "y_train_pred = regr_tags.predict(X_train_tags)\n",
    "\n",
    "print(\"Erreur au carré moyenne d'entraînement: %.4f\"\n",
    "      % mean_squared_error(y_train_tags, y_train_pred))\n",
    "\n",
    "# Obtenir les prédictions de test\n",
    "y_test_pred = regr_tags.predict(X_test_tags)\n",
    "\n",
    "print(\"Erreur au carré moyenne de test: %.4f\"\n",
    "      % mean_squared_error(y_test_tags, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À noter: l'erreur de test est de 0.99 pour ce modèle (2.3) comparé à une erreur MSE de test de 1.03 pour le modèle 2.2. Les tags semblent offrir une performance légèrement supérieure, mais elles ont aussi besoin d'un modèle d'une plus grande taille (968 paramètres en plus à estimer) ce qui prend environ 30% en plus à optimiser. Évidemment, ce n'est pas une comparaison exacte et elle dépend de votre ordinateur. Ceci étant dit, il semble quand même que l'algorithme d'estimation n'est pas linéaire (c.-à-d., augmenter le nombre de paramètres par 10%, augmente la durée de l'estimation par 30%).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Apprendre un modèle non linéaire\n",
    "\n",
    "Pour l'instant nous avons étudié l'effet d'utiliser différents attributs sur un modèle linéaire. Il semble qu'ajouter des attributs aide à obtenir une meilleure performance de généralisation.\n",
    "\n",
    "Maintenant nous explorerons un modèle non linéaire, un réseau de neurones à une couche cachée (les réseaux de neurones seront le thème des deux prochaines semaines). La tâche est les données ne changent pas, seulement le modèle.\n",
    "\n",
    "**Le b.a.-ba des réseaux de neurones:** \n",
    "- Un réseau de neurones est constitué de neurones interconnectés. Chaque neurone n'effectue que quelques calculs simples. \n",
    "- Dans un réseau *feed-forward*, les neurones sont organisés dans des ensembles appelés couches (*layers*). \n",
    " - Les neurones de chaque couche obtiennent leurs entrées des neurones de la couche précédente. Les neurones d'une couche envoient donc le résultat de leur calcul à la couche d'après. \n",
    " - La première couche est appelée couche entrante (*input layer*) elle utilise directement les données et les passent à la seconde couche. La dernière couche est celle de sortie (*output layer*) elle calcule les prédictions finales $\\hat{y}$. \n",
    " - Les couches entre la couche d'entrée et de sortie sont appelées les couches cachées (*hidden layers*). Chaque neurone des couches cachées est un modèle linéaire suivit d'une fonction d'activation non linéaire (*activation function*): $f(x) = \\sum_i x_i \\theta_i$. \n",
    "  - Le nombre de neurones des couches d'entrée et de sortie est fixé par les données (le nombre des attributs et le nombre de prédictions par exemple). \n",
    "  - Le nombre de neurones de chaque couche cachée est un hyper paramètre. Un autre hyper paramètre est le nombre de couches cachées.\n",
    "\n",
    "Mathématiquement, pour une tâche de régression (avec une seule prédiction par exemple), un réseau de neurones à une couche cachée est: \n",
    "$$ \n",
    "f(x) = f_\\text{o} ( \\sum_{j=0}^{|\\text{hidden n.}|} \\theta'_{j} f_\\text{h}( \\sum_{i=0}^{|p|}\\theta_{ij} x_i ) ) \n",
    "$$ \n",
    "avec\n",
    "- $\\theta_{ij}$ les paramètres des entrées $i$ et neurone $j$ d'une couche cachée.\n",
    "- $f_h$ est la fonction d'activation d'une couche cachée\n",
    "- $\\theta'_{j}$ sont les paramètres qui connectent le neurone $j$ de la couche cachée à la couche de sortie.\n",
    "- $f_o$ est la fonction d'activation de la couche de sortie\n",
    "\n",
    "\n",
    "Il peut être plus intuitif de visualiser l'architecture d'une réseau de neurones en dessinant les neurones comme étant de noeuds et les connections comme des arrêtes dans un graphe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un réseau de neurones à une couche cachée où l'entrée à 10 dimensions (p=10) et la sortie une seule dimension\n",
    "input_dims = 10 # p \n",
    "# nombre de neurones cachées pour chaque couche cachée (pour ajouter une couche il faut ajouter une dimension)\n",
    "hidden_layers_size = [4] \n",
    "output_dims = 1 # nombre de sorties\n",
    "\n",
    "network = DrawNN( [input_dims] + hidden_layers_size + [output_dims] )\n",
    "network.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Créer un réseau de neuronnes\n",
    "regr_nn = neural_network.MLPRegressor(alpha=0.1, # l2-regularization (weight decay)\n",
    "                                      hidden_layer_sizes=tuple(hidden_layers_size),\n",
    "                                      early_stopping=True, # stop if validation performance decreases\n",
    "                                      verbose=True,\n",
    "                                      random_state=1234)\n",
    "\n",
    "# Estimer les paramètres du réseau sur nos données\n",
    "\n",
    "#normalize data\n",
    "start = time.time()\n",
    "regr_nn.fit(X_train_tags, y_train_tags)\n",
    "fit_time = time.time() - start\n",
    "\n",
    "print(\"Temps d'apprentissage du modèle: %.2f seconds\" % fit_time)\n",
    "print(\"Nombre de paramètres:\", reduce(lambda x,y: x+y, \n",
    "                                       list(map(lambda x: x.size, regr_nn.coefs_+regr_nn.intercepts_)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les autres modèles, nous pouvons régulariser les paramètres du réseau pour éviter le surentrainement:\n",
    "- Nous utilisons la même taille du régularisateur L2 pour tous les paramètres. La taille du régularisateur est donnée par $\\alpha$. \n",
    "- En plus, nous utilisons un second régularisateur qui se nomme `early-stopping`. L'apprentissage des paramètres dans un réseau de neurones est une procédure littérature en utilisant une méthode appelée descente de gradient (par rapport à la régression linéaire, il n'existe pas de solution analytique permettant de trouver les paramètres optimaux en fonction de la fonction d'objectif). Le *Early stopping* évalue simplement une erreur de validation après chaque itération d'entraînement. La procédure stoppe l'apprentissage une fois que l'erreur de validation arrête de progresser. Ceci peut évidemment arriver avant que l'erreur d'entraînement converge. Si ce n'est pas le cas, ce régularisateur n'a aucun effet sur l'apprentissage. Dans `scikit-learn`, la classe `MLPRegressor` avec `early_stopping=True` divise automatiquement l'ensemble d'entraînement en deux (validation et entraînement). Le désavantage évidemment est qu'il reste un tout petit moins de données pour s'entraîner.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Pourquoi dans `sklearn` ce modèle permet-il de fixer une racine (c.-à-d., `random_state`) alors que le modèle de régression linéaire ne le permet pas? \n",
    "\n",
    "**Réponse:** La régression linéaire n'a qu'une seule solution (c-à-d., peu importe l'initialisation des paramètres , la solution sera la même). Ce n'est en général pas le cas pour les réseaux de neurones. En pratique, une bonne initialisation peut faire une grande différence sur la généralisation du modèle (il existe d'ailleurs beaucoup d'heuristiques d'initialisation pour tenter d'obtenir des solutions qui généralisent le mieux possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions d'entraînement\n",
    "y_train_pred = regr_nn.predict(X_train_tags)\n",
    "#y_train_pred = regr_nn.predict(scaler.transform(X_train_tags))\n",
    "\n",
    "\n",
    "print(\"Erreur au carré moyenne d'entraînement: %.4f\"\n",
    "      % mean_squared_error(y_train_tags, y_train_pred))\n",
    "\n",
    "# Obtenir les prédictions de test\n",
    "y_test_pred = regr_nn.predict(X_test_tags)\n",
    "#y_test_pred = regr_nn.predict(scaler.transform(X_test_tags))\n",
    "\n",
    "print(\"Erreur au carré moyenne de test: %.4f\"\n",
    "      % mean_squared_error(y_test_tags, y_test_pred))\n",
    "#Train Mean squared error: 0.6623\n",
    "#Test Mean squared error: 1.0465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici notre tableau des résultats\n",
    "\n",
    "| Modèle        | MSE de test           |\n",
    "| ------------- |:-------------:| \n",
    "| 2.2 (Reg. linéaire avec attributs)     | 1.031 | 0.8650  |\n",
    "| 2.3 (2.2 + *tags* des films)     | 0.991 | 0.8571 |\n",
    "| 2.4 (Réseau de neurones avec les attributs de 2.3) | 1.029 | 0.8650 | \n",
    "\n",
    "Même si les réseaux de neurones sont très puissants (leur capacité est haute), sur cette tâche le réseau de neurones entraîné n'améliore pas la performance d'un modèle de régression plus simple. Ce n'est évidemment pas indicatif de la performance de tous les réseaux de neurones (il est possible qu'une réseau de neurones un peu différents obtiennent de meilleurs résultats). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"concluding-remarks\"></a>\n",
    "### Section 3. Conclusions\n",
    "\n",
    "Le but de ce tutoriel était de vous introduire à l'apprentissage automatique de manière très pratique et de complémenter le cours. Nous nous pencherons évidemment en détail sur les réseaux de neurones dans les semaines à venir.\n",
    "\n",
    "Avant de terminer: \n",
    "\n",
    "#### Apprentissage automatique\n",
    "\n",
    "Comme vous avez pu le constater, l'apprentissage machine pratique est très empirique. Une fois que vous avez des données dans un format correct, il est typique de les utiliser pour estimer et comparer différents modèles. Vous pouvez tenter de comprendre les avantages/désavantages de ces modèles dans votre contexte. C'est aussi une bonne manière de mieux comprendre vos données. En pratique, c'est souvent un aspect essentiel que nous n'avons pas énormément abordé dans ce tutoriel (au profit d'une meilleure exploration des modèles).\n",
    "\n",
    "\n",
    "#### Scikit-learn\n",
    "`scikit-learn` est une libraire de ML très pratique et puissant. C'est une boîte à outils de modèles ainsi que de routines pour prétraiter vos données. Elle offre une interface à une grande variété de modèles, elle reste activement développée et en général c'est une excellente plateforme. C'est aussi une libraire ouverte (*open source*) et gratuite à utiliser. \n",
    "\n",
    "Sélection de modèles: choisir le meilleur (ou même un bon) modèle pour une tâche particulière n'est pas une mince affaire. [Cette page](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) offre des conseils pour la sélection de modèles disponibles sur `scikit-learn`. N'oubliez pas qu'en pratique, la performance de test n'est souvent qu'une seule mesure parmi d'autres (qui peuvent inclure, par exemple, le temps d'estimation du modèle, le taux de faux positif ou faux négatifs, etc.)\n",
    "\n",
    "Bien que très versatile, `scikit-learn` n'est pas utilisable pour tout. Par exemple, cette libraire n'offre que très peu de réseaux de neurones modernes. Ce n'est pas non plus, la plateforme idéale pour développer de nouveaux modèles.\n",
    "\n",
    "#### D'autres libraires\n",
    "\n",
    "La qualité des logiciels disponibles a largement contribué à la popularité de l'apprentissage automatique dans les dernières années. Les logiciels modernes automatisent une série de tâches qui permettent aux programmeurs d'être plus efficaces. `scikit-learn` est un outil très populaire, mais il existe évidemment d'autres librairies de bonne qualité (tant pour utiliser des modèles existants que pour développer de nouveaux modèles). Il peut évidemment être pratique et tentant d'apprendre plusieurs de ces librairies. À mon avis, c'est encore plus important d'avoir une compréhension des fondamentaux de l'apprentissage automatique d'autant plus que les librairies changent souvent très rapidement. \n",
    "\n",
    "#### Matière à réflexion\n",
    " - Dans nos modèles nous avons pris comme hypothèse que les notes sont les variables dépendantes (y) et que nous avions accès à des attributs des utilisateurs et des items. Imaginone une tâche où nous n'aurions pas accès à des attributs, ou bien à un cas où les attributs ne seraient pas informatifs des notes. Dans ce cas, le modèle de régression linéaire deviendrait: \n",
    " \n",
    "$$\n",
    "f(x_{ui}) = \\theta_\\text{uid} x_{\\text{uid}_u} + \\theta_{\\text{mid}} x_{\\text{mid}_i}\n",
    "$$ \n",
    " \n",
    "\n",
    "- **Question 7:** Quel est le problème avec ce dernier modèle? Je vous suggère d'y réfléchir un peu avant de lire la réponse. \n",
    "\n",
    "- **Réponse possible:** (il y en a d'autres)\n",
    "    - Il n'y aucune interaction entre les utilisateurs et les items. Prenons l'exemple d'un utilisateur, cet utilisateur contribuera un coefficient $\\theta_{\\text{uid}_u}$ fix peu importe le film. Ce modèle ne modélisera que la note moyenne de l'utilisateur (idem pour les paramètres des films qui modéliseront leur popularité). L'effet sera que les recommandations seront les mêmes pour tous les utilisateurs.\n",
    "     - A la place, vous pourriez imaginer introduire une interaction entre les utilisateurs et les items. P. ex., \n",
    "     \n",
    "     $$x_{\\text{uid}_u} * x_{\\text{mid}_i} * \\theta_{\\text{uid}_u} * \\theta_{\\text{mid}_i}.$$\n",
    "\n",
    "       Ce genre d'interaction arrivera de manière naturelle dans les réseaux de neurones (je vous laisse vous convaincre). Pendant la semaine 11 nous parlerons aussi d'un modèle nommé [factorisation de matrice](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf) qui utilise cette intuition.\n",
    "\n",
    "- Comme nous le verrons à la semaine 11 (sur les systèmes de recommandation), il existe plusieurs modèles qui utilisent les notes en entrée **et** en sortie. Par exemple, on pourrait directement utiliser les notes historiques d'un utilisateur pour prédire ses notes futures  (pour ce faire on pourrait utiliser un auto-encodeur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "\n",
    "Scikit-learn (en anglais)\n",
    "- [Documentation](https://scikit-learn.org/stable/documentation.html)\n",
    "- [Tutoriels](https://scikit-learn.org/stable/tutorial/index.html)\n",
    "- [Aide à la sélection de modèles](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
