{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "#from pyspark.ml.classification import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train = spark.read.option(\"sep\", \"\\t\").csv(\"gs://80-629bucket/dat/criteo/data.txt\", inferSchema=True)\n",
    "raw_train = raw_train.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_full = raw_train.fillna(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45840617"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|               _c0|               _c1|               _c2|               _c3|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|          45840617|          25047061|          45840617|          36001170|\n",
      "|   mean|0.2562233837297609|3.5024133170754044|105.84841979766546|26.913041020611274|\n",
      "| stddev|0.4365466361308114| 9.429076407105068| 391.4578226870709|397.97258302273343|\n",
      "|    min|                 0|                 0|                -3|                 0|\n",
      "|    max|                 1|              5775|            257675|             65535|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_train.describe([\"_c0\", \"_c1\", \"_c2\", \"_c3\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#raw_train.describe(\"_c0\").show()\n",
    "#raw_train_full = raw_train_full.withColumn('label', (raw_train_full._c0 > 0).cast(\"int\"))\n",
    "#print(raw_train_full.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  45840617\n",
      "[Row(_c0=0, features=DenseVector([1.0, 1.0, 5.0, 0.0, 1382.0, 4.0, 15.0, 2.0, 181.0, 1.0, 2.0, 0.0])), Row(_c0=0, features=DenseVector([2.0, 0.0, 44.0, 1.0, 102.0, 8.0, 2.0, 2.0, 4.0, 1.0, 1.0, 0.0])), Row(_c0=0, features=DenseVector([2.0, 0.0, 1.0, 14.0, 767.0, 89.0, 4.0, 2.0, 245.0, 1.0, 3.0, 3.0])), Row(_c0=0, features=SparseVector(12, {1: 893.0, 4: 4392.0})), Row(_c0=0, features=SparseVector(12, {0: 3.0, 1: -1.0, 4: 2.0, 6: 3.0, 9: 1.0, 10: 1.0})), Row(_c0=0, features=SparseVector(12, {1: -1.0, 4: 12824.0, 8: 6.0})), Row(_c0=0, features=SparseVector(12, {1: 1.0, 2: 2.0, 4: 3168.0, 7: 1.0, 8: 2.0})), Row(_c0=1, features=SparseVector(12, {0: 1.0, 1: 4.0, 2: 2.0, 6: 1.0, 9: 1.0, 10: 1.0})), Row(_c0=0, features=DenseVector([0.0, 44.0, 4.0, 8.0, 19010.0, 249.0, 28.0, 31.0, 141.0, 0.0, 1.0, 0.0])), Row(_c0=0, features=DenseVector([0.0, 35.0, 0.0, 1.0, 33737.0, 21.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0]))]\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\", \"_c7\", \"_c8\", \"_c9\", \"_c10\", \"_c11\", \"_c12\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "# Spark: Transformer\n",
    "raw_data_features = assembler.transform(raw_train_full)\n",
    "output_ = raw_data_features.select(\"_c0\",\"features\")\n",
    "\n",
    "print('number of examples: ', output_.count())\n",
    "\n",
    "print(output_.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 41255651\n",
      "test size: 4584966\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = output_.randomSplit([0.9, 0.1])\n",
    "trainingData = trainingData.cache()\n",
    "testData = testData.cache()\n",
    "print('train size:', trainingData.count())\n",
    "print('test size:', testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 40.633 seconds\n"
     ]
    }
   ],
   "source": [
    "stime = time.time()\n",
    "\n",
    "# ML model (Spark: estimator)\n",
    "lr = LogisticRegression(maxIter=100, regParam=1e-10, labelCol=\"_c0\")\n",
    "# Fit the model\n",
    "lrModel = lr.fit(trainingData)\n",
    "etime = time.time()\n",
    "print('Elapsed time: %.3f seconds' % (etime-stime)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0 0.5691069258913035\n",
      "1 0.5549827944687944\n",
      "2 0.5423720516435322\n",
      "3 0.5397960766369744\n",
      "4 0.5386946905229483\n",
      "5 0.5385758953810765\n",
      "6 0.538470190181823\n",
      "7 0.5384230099835767\n",
      "8 0.5383677162964634\n",
      "9 0.5383329720387219\n",
      "10 0.5383283343558296\n",
      "11 0.5383279064070904\n",
      "12 0.5383278374137921\n",
      "13 0.5383277506498904\n",
      "14 0.5383277069077383\n",
      "15 0.5383277018928259\n",
      "16 0.5383277008852546\n",
      "17 0.5383277007277508\n",
      "18 0.5383277005758531\n",
      "19 0.5383277005231083\n",
      "20 0.5383277005131621\n",
      "21 0.5383277005086056\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c001b5dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "objectives = []\n",
    "for i, objective in enumerate(objectiveHistory):\n",
    "    print(i, objective)\n",
    "    objectives.append(objective)\n",
    "    \n",
    "plt.plot(np.arange(len(objectives)), np.array(objectives))\n",
    "plt.show()\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "#trainingSummary.roc.show()\n",
    "#print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[  7.23768337e-03,   1.47586658e-04,   1.02208080e-04,\n",
      "               -2.01836583e-02,  -3.72183812e-06,  -5.75158880e-04,\n",
      "               -2.20907122e-03,  -1.06814144e-02,   5.65470616e-06,\n",
      "                5.07626629e-01,   5.95487132e-02,   3.07151972e-02]])\n",
      "Coefficients: [0.00723768336571,0.000147586657843,0.000102208080257,-0.0201836582754,-3.72183812415e-06,-0.000575158880462,-0.00220907122013,-0.0106814144048,5.65470616265e-06,0.507626628779,0.0595487131591,0.0307151971702]\n",
      "Intercept: -1.1005271025328507\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(lrModel.coefficientMatrix)\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "#print(\"lrModel was fit using parameters: \")\n",
    "#print(lrModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|                _c0|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|            4584966|            4584966|\n",
      "|   mean|0.25590745929195546|0.03542120050617605|\n",
      "| stddev|0.43637011022964606|0.18484195008910198|\n",
      "|    min|                  0|                0.0|\n",
      "|    max|                  1|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n",
      "Logistic Regression\n",
      "Test Error = 0.253252 \n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "#testData.describe().show()\n",
    "predictions.describe().show()\n",
    "\n",
    "# Select example rows to display.\n",
    "#predictions.select(\"prediction\", \"_c0\", \"features\").show(50)\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"_c0\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Logistic Regression\\nTest Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 18.815 seconds\n"
     ]
    }
   ],
   "source": [
    "stime = time.time()\n",
    "\n",
    "# ML model (Spark: estimator)\n",
    "dt = DecisionTreeClassifier(labelCol=\"_c0\", featuresCol=\"features\")\n",
    "# Fit the model\n",
    "dtModel = dt.fit(trainingData)\n",
    "etime = time.time()\n",
    "print('Elapsed time: %.3f seconds' % (etime-stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "5\n",
      "(12,[0,2,3,4,5,6,7,8,10],[0.362085102677,0.0308000146908,0.026081081763,0.017491095317,0.265703987045,0.0338906179492,0.031822641098,0.0124551478223,0.219670311638])\n"
     ]
    }
   ],
   "source": [
    "print(dtModel.numNodes)\n",
    "print(dtModel.depth)\n",
    "print(dtModel.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|prediction|_c0|  features|\n",
      "+----------+---+----------+\n",
      "|       0.0|  0|(12,[],[])|\n",
      "|       0.0|  0|(12,[],[])|\n",
      "|       0.0|  0|(12,[],[])|\n",
      "|       0.0|  0|(12,[],[])|\n",
      "|       0.0|  0|(12,[],[])|\n",
      "+----------+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = dtModel.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"_c0\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Test Error = 0.244372 \n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4105a2600173c6b8f8cd) of depth 5 with 63 nodes\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"_c0\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Decision Tree\\nTest Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "#treeModel = dtModel.stages[2]\n",
    "# summary only\n",
    "print(dtModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Data type StringType is not supported.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o267.transform.\n: java.lang.IllegalArgumentException: Data type StringType is not supported.\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$transformSchema$1.apply(VectorAssembler.scala:121)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$transformSchema$1.apply(VectorAssembler.scala:117)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:117)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:54)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5930e6e04ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0;34m\"_c28\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c29\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c30\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c31\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c32\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c33\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c34\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"_c35\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                \"_c36\",  \"_c37\",  \"_c38\"],\n\u001b[0;32m---> 16\u001b[0;31m     outputCol=\"features\").transform(data)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Index labels, adding metadata to the label column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Data type StringType is not supported.'"
     ]
    }
   ],
   "source": [
    "#from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load the data stored in CSV format as a DataFrame.\n",
    "data = spark.read.option(\"sep\", \"\\t\").csv(\"gs://80-629bucket/dat/criteo/data.txt\", inferSchema=True)\n",
    "\n",
    "data = data.fillna(0.1)\n",
    "data = VectorAssembler(\n",
    "    inputCols=[\"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\", \"_c7\", \"_c8\", \"_c9\", \"_c10\",\\\n",
    "               \"_c11\", \"_c12\", \"_c13\", \"_c14\", \"_c15\", \"_c16\", \"_c17\", \"_c18\",  \"_c19\",\\\n",
    "               \"_c20\",  \"_c21\",  \"_c22\",  \"_c23\",  \"_c24\",  \"_c25\",  \"_c26\",  \"_c27\",\\\n",
    "               \"_c28\",  \"_c29\",  \"_c30\",  \"_c31\",  \"_c32\",  \"_c33\",  \"_c34\",  \"_c35\",\\\n",
    "               \"_c36\",  \"_c37\",  \"_c38\"],\n",
    "    outputCol=\"features\").transform(data)\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(data) #, maxCategories=4).fit(data)\n",
    "\n",
    "data = featureIndexer.transform(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a logistic regression model\n",
    "#dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01, featuresCol=\"indexedFeatures\", labelCol=\"_c0\")\n",
    "# Fit the model\n",
    "#lrModel = lr.fit(output_)\n",
    "\n",
    "# Chain indexers and logistic regressos in a Pipeline\n",
    "#pipeline = Pipeline(stages=[featureAssembler, featureIndexer, lr])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "#model = pipeline.fit(trainingData)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = lr.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "dataset = spark.createDataFrame(\n",
    "    [(0, 18, 1.0, Vectors.dense([0.0, 10.0, 0.5]), 1)],\n",
    "    [\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\"])\n",
    "\n",
    "print(dataset.printSchema())\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"hour\", \"mobile\", \"userFeatures\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(dataset)\n",
    "print(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")\n",
    "output.select(\"features\", \"clicked\").show(truncate=False)\n",
    "\n",
    "print(output.printSchema())\n",
    "\n",
    "stime = time.time()\n",
    "lr = LogisticRegression(maxIter=2, regParam=0.3, elasticNetParam=0.8, labelCol=\"clicked\")\n",
    "# Fit the model\n",
    "lrModel = lr.fit(output)\n",
    "etime = time.time()\n",
    "print('total time: %.3f seconds' % (etime-stime)) \n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = sc.textFile('gs://80-629bucket/dat/criteo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"gs://80-629bucket/dat/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(training.show())\n",
    "print(training.schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
