{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "from utils import generate_data, plot_predictions, plot_svc_decision_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this practical session we will explore several classification  models. But first, as usual, let's generate and plot some training and testing data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train, datasets_test = generate_data()\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax1 = fig.add_subplot(2, 3, 1)\n",
    "ax1.set_title(\"Dataset 1\")\n",
    "ax1.scatter(datasets_train[0][0][:,0],datasets_train[0][0][:,1], c=datasets_train[0][1], marker=\"s\", label='train')\n",
    "ax1.scatter(datasets_test[0][0][:,0],datasets_test[0][0][:,1], c=datasets_test[0][1], marker=\"+\", label='test')\n",
    "legend1 = ax1.legend(loc=\"upper left\")\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "ax2 = fig.add_subplot(2, 3, 2)\n",
    "ax2.set_title(\"Dataset 2\")\n",
    "ax2.scatter(datasets_train[1][0][:,0],datasets_train[1][0][:,1], c=datasets_train[1][1], marker=\"s\", label='train')\n",
    "ax2.scatter(datasets_test[1][0][:,0],datasets_test[1][0][:,1], c=datasets_test[1][1], marker=\"+\",  label='test')\n",
    "ax2.legend(loc='upper left');\n",
    "\n",
    "ax3 = fig.add_subplot(2, 3, 3)\n",
    "ax3.set_title(\"Dataset 3\")\n",
    "ax3.scatter(datasets_train[2][0][:,0],datasets_train[2][0][:,1], c=datasets_train[2][1], marker=\"s\", label='train')\n",
    "ax3.scatter(datasets_test[2][0][:,0],datasets_test[2][0][:,1], c=datasets_test[2][1], marker=\"+\",  label='test')\n",
    "ax3.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Linear least squares for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous practical session we explored how to tune a linear regression using least-squares loss function. We saw that minimization of the least-squares loss function led to a simple closed-form solution (see also Week #2 Slide 31). \n",
    "\n",
    "As discussed in class, similar idea can also be applied to the classification task, with the difference that now we additionally require a decision rule for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in class, let the decision rule be simply $sign(y(x))$, where $y(x) = W^Tx$ is our discriminant function. Thus, such a classifier will return class '+' for all the points lying on one side of the decision boundary and '-' for the ones lying on the other side. Let's implement this simple classifier. We will encode the two classes as '-1' and '+1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#least squares for classification\n",
    "def train_LSC(X, Y):\n",
    "    #Note: we transform the labels from {0,1} to {-1,+1}\n",
    "    Y = (ds_train[1]*2)-1\n",
    "    \n",
    "    #calculate the discriminant function parameters\n",
    "    W = np.linalg.inv(X.T @ X) @ (X.T @ Y.reshape(100,1))\n",
    "    return W\n",
    "\n",
    "def calculate_decision_boundary(W):\n",
    "    line_x = np.linspace(-10,10) # <- this would give x1;\n",
    "    #the goal is to calculate x2 given x1 and the weights\n",
    "    \n",
    "    line_y = None #TODO <- complete this line\n",
    "    return line_x, line_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ds_train, ds_test) in enumerate(zip(datasets_train, datasets_test)):\n",
    "    ds_train = datasets_train[i]\n",
    "    ds_test = datasets_test[i]\n",
    "\n",
    "    X = ds_train[0]\n",
    "    #Add a column of ones to account for the bias term\n",
    "    X_b = np.array([np.ones(len(X)), X[:,0], X[:,1]]).T\n",
    "    ####\n",
    "    Y = ds_train[1]\n",
    "    X_test = ds_test[0]\n",
    "\n",
    "    #Add a column of ones to account for the bias term\n",
    "    X_test_b = np.array([np.ones(len(X_test)), X_test[:,0], X_test[:,1]]).T\n",
    "    ###\n",
    "\n",
    "    Y_test = ds_test[1]\n",
    "\n",
    "    # 1) train weights\n",
    "    #let k be the number of casses (2), dim - dimentionality of the data (2)\n",
    "    W = train_LSC(X_b, Y) # dim x k\n",
    "\n",
    "    # 2) Calculate the discriminant function and predict \n",
    "    # a) for test data\n",
    "    y_x = np.dot(W.T, X_test_b.T)\n",
    "    pred_test = 1*(y_x>0)[0]\n",
    "\n",
    "    # b) for training data\n",
    "    y_x = np.dot(W.T, X_b.T)\n",
    "    pred_train = 1*(y_x>0)[0]\n",
    "\n",
    "    \n",
    "    # 3) Calculate decision boundary\n",
    "    line_x, line_y = calculate_decision_boundary(W)\n",
    "    \n",
    "    \n",
    "    # 4) plot predictions\n",
    "    plot_predictions(i,X,Y, X_test, Y_test, pred_train, pred_test, line_x, line_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** for which dataset does the model achieve the best performance? Explain in your own words, why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** complete the **\"calculate_decision_boundary\"** function above to produce the decision boundary for the classifiers. Rerun the cell above to see the correct decision boundary.\n",
    "\n",
    "Hint:\n",
    "1. Set up the discriminant function: $y(\\vec{x}) = W^T\\vec{x}$.  \n",
    "2. What is the decision rule? (i.e. which output of the discrimnant function would imply \"uncertainty\")?\n",
    "3. Solve for $x_2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the sklearn library for the first time. We will train and evaluate a Suport Vector Machine (SVM) model, whih was brefly touched upon in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's generate some clearly linearly seperable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's load the linearly seperable dataset\n",
    "X, Y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                               random_state=1, n_clusters_per_class=1)\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "xfit = np.linspace(-2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y)\n",
    "\n",
    "for m, b, d in [(1.5, 1, 0.2), (10, 1, 2), (-1.5, 1.2, 0.2)]:\n",
    "    yfit = m * xfit + b\n",
    "    plt.plot(xfit, yfit, '-k')\n",
    "    plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none',\n",
    "                     color='#AAAAAA', alpha=0.4)\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-0.5,2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there axist many decision boundaries can be used to seperate the given dataset.\n",
    "\n",
    "SVM choses the line that maximizes the margin to the closest point. Let's use sklearn to train an SVM model and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the SVM classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "\n",
    "#let us fit the model (learn its parameters)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X[:, 0], X[:, 1], c = Y)\n",
    "ax = plot_svc_decision_function(model,ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model has chosen the decision boundary with the maximal margin. Here, the pivot elements that touch the (dotted) margins are called support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to classify our linearly seperable dataset from before using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = datasets_train[2]\n",
    "\n",
    "# create an sklearn model object\n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "\n",
    "#let's fit the model (learn its parameters)\n",
    "model.fit(X, Y)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y)\n",
    "plot_svc_decision_function(model,ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in our linearly seperable dataset, the datapoints from the two classes overlap and there is no perfect decision boundary for our SVM model.\n",
    "\n",
    "We can also see that for the classifier (decision boundary) depicted in the above graph no margin is visualized, as there are no suport vectors that can setisfy the 'hard margin' condition.\n",
    "\n",
    "To deal with the overlapping datasets, a 'soft-margin' version of the SVM can be implemented varying the regularization strength applied during the training. This would allow some points to enter the margin, leading to a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question SVM:** check the documentation of the sklearn SVM classifier [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). Try to find the parameter that would control the regularization strength and change it in the cell above to implement a \"soft-margin\" SVM. Rerun the cell to visualize the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the SVM classifier on all the 3 datasets (*Note: please complete the previous question first, otherwise this next cell will run for a long time*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ds_train, ds_test) in enumerate(zip(datasets_train, datasets_test)):\n",
    "    ds_train = datasets_train[i]\n",
    "    ds_test = datasets_test[i]\n",
    "\n",
    "    X = ds_train[0]\n",
    "    Y = ds_train[1]\n",
    "    \n",
    "        \n",
    "    X_test = ds_test[0]\n",
    "    Y_test = ds_test[1]\n",
    "    # 1) train weights\n",
    "    #let's fit the model (learn its parameters)\n",
    "    #we use the model form the cell above\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    # 2) Calculate the discriminant function and predict \n",
    "    # a) for test data\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    # b) for training data\n",
    "    y_x = np.dot(W.T, X_b.T)\n",
    "    pred_train = model.predict(X)\n",
    "\n",
    "    \n",
    "    # 4) plot predictions\n",
    "    plot_predictions(i,X,Y, X_test, Y_test, pred_train, pred_test, plot_svm=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the previously seen classifiers were coming up with a linear decision boundary. Here we will implement the Naive Bayes classifier, that was extensively discussed in class, and see if this classifier can come up with better decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our toy datasets, the target variables $y \\in \\{0,1 \\}$ are categorical, and hence, can be modeled with a *Categorical* distribution $p(y=k|\\pi_k)$. Our feature variables $x \\in \\mathbb{R}^2$ are continuous variables. As discussed in the class, we can model continuous variables with a Gaussian distribution $\\mathcal{N}(x_j | \\mu_{jk}, \\sigma^2_{jk})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: in the following the fitting procedure for a Naive Bayes classifier is described. Fill in the gaps with missing text (double-click on this cell to be able to edit in the text).\n",
    "    \n",
    "   1. Calculate MLE estemates for all the parameters of our distributions: \n",
    "     $\\theta \\in \\{$<font size=\"2\" color='red'> $  \\text{fill in the parameters here}   $ </font> \\} using the training set.\n",
    "   2. Use the estimated parameters and the <font size=\"2\" color='red'> fill in the theorem name here  </font> theorem to make predictions. The corresponding formula is:\n",
    "   \n",
    "   $posterior  \\propto join = class\\space conditional * class\\space prior$\n",
    "   \n",
    "   $P(y = k|x) \\propto$  <font size=\"2\" color='red'> fill in the formula here  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building the naive Bayes model for our second dataset. Later, we can easily train and test our implementation on all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8155c7f2f848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#we use the 2 circles dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#class indicies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi_c0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi_c1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets_train' is not defined"
     ]
    }
   ],
   "source": [
    "X, Y = datasets_train[1] #we use the 2 circles dataset\n",
    "\n",
    "#class indicies\n",
    "i_c0 = (Y == 0)\n",
    "i_c1 = (Y == 1)\n",
    "\n",
    "X_0 = X[i_c0] #data of class 0\n",
    "X_1 = X[i_c1] #data of class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by calculating the prior probability for each class. As seen in the class, the MLE estimate for the categorical prior is simply given by:\n",
    "\n",
    "$\\hat{\\pi}_k = \\frac{N_k}{N}$\n",
    "\n",
    "Fill in missing code in the following cell to calculate the prior probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prios(X_0, X_1, X):\n",
    "    # TODO: calculate prior class 0 \n",
    "    prior_k0 =  0 \n",
    "\n",
    "\n",
    "    # TODO: calculate prior class 1\n",
    "    prior_k1 = 0\n",
    "\n",
    "    #let's store the priors in a dictionary\n",
    "    prior_dict = {0:prior_k0 , 1:prior_k1  }\n",
    "    \n",
    "    return prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dict = calculate_prios(X_0, X_1, X)\n",
    "print(prior_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the MLE for the parameters of a Gaussian. We can call each dimension of our input dataset X a *feature*.\n",
    "\n",
    "As elaborated e.g. [here](https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood), the maximum likelihood estimates of the **mean** is simply the empirical mean:\n",
    "\n",
    "$\\hat{\\mu} = \\frac{1}{n} \\sum_{i=0}^{n} x^{(i)}$. For our algorithm we need to calculate this quantity for each class ($k$) and for each feature ($j$):\n",
    "\\begin{align}\n",
    "    \\hat{\\mu}_{jk} = \\frac{\\sum_{i=0}^{n} \\mathbb{1}(y^{(i)}=k) x_{j}^{(i)}}{ \\sum_{i=0}^{n} \\mathbb{1}(y^{(i)}=k)} \n",
    "\\end{align}\n",
    "(*Note, $\\mathbb{1}(y^{(i)}=k)$ evaluates to 1 only if $y^{(i)}=k$.*)\n",
    "\n",
    "\n",
    "Further, the MLE of the *variance* of a Gaussian distribution is simply the empirical variance: \n",
    "\n",
    "$\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{j=0}^{n} (x^{(j)} - \\mu)^2$\n",
    "\n",
    "(*Note, also the variance needs to be calculated per class per feature using our training data.*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: complete the implementation of the MLE estimates in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MLE(X_0,X_1):\n",
    "    #Calculate statistics for features per class\n",
    "    class_summaries = dict()\n",
    "\n",
    "    feat_0_class_0 = np.mean(X_0[:,0]), np.std(X_0[:,0])\n",
    "    feat_1_class_0 = np.mean(X_0[:,1]), np.std(X_0[:,1])\n",
    "\n",
    "    #put them in the summaries dictionary\n",
    "    class_summaries[0] = [feat_0_class_0, feat_1_class_0]\n",
    "\n",
    "    feat_0_class_1 = [0,0] #TODO <- complete this line by calculating the statistics for class 1 feature 0\n",
    "    feat_1_class_1 = [0,0] #TODO <- complete this line by calculating the statistics for class 1 feature 1\n",
    "    \n",
    "    #put them in the summaries dictionary\n",
    "    class_summaries[1] = [feat_0_class_1, feat_1_class_1]\n",
    "    return class_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_summaries = calculate_MLE(X_0, X_1)\n",
    "print(class_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, we have completed the training procedure of our Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's make predictions using our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we assumed that our features are drawn from Gaussian distributions, we need to implement the Gaussian probability density function (pdf) that will return the probability of the input for a given mean and variance parameters (we will use the per class MLE parameters estimated earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\mathcal{N}(x,\\mu,\\sigma) = \\frac{1}{ \\sigma \\sqrt{2 \\pi}} e^{\\left(-\\frac{{\\left(\\mu - x\\right)}^{2}}{2 \\, \\sigma^{2}}\\right)} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_PDF(x, mean, stdev):\n",
    "    exponent = np.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply our model to a single test point. \n",
    "\n",
    "Remember, all we need to do is to apply the Bayes theorem using the parameters we estimated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test point\n",
    "test_point = X[2]\n",
    "print(test_point)\n",
    "print(f'value of feature 1: {test_point[0]}, value of feature 2: {test_point[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** complete the function in the cell below that calculates the posterior probability for a given test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_probability(x_test, class_summaries, prior_dict):\n",
    "    # we will store our resulting probabilities in this dictionary:\n",
    "    resulting_probabilities = dict() \n",
    "    \n",
    "    \n",
    "    for c, class_stats in class_summaries.items():\n",
    "\n",
    "        prior_c= prior_dict[c]\n",
    "        resulting_probabilities[c] = prior_c # put P(y) in the dictionary containing the result\n",
    "\n",
    "        for i, feature_stat in enumerate(class_stats):\n",
    "            mean, stdev = feature_stat\n",
    "            resulting_probabilities[c] *= 0 #TODO <- complete this line, here the posterior for the test sample should be calculated\n",
    "    \n",
    "    return resulting_probabilities\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = calculate_probability(test_point, class_summaries, prior_dict)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: describe why the Naive Bayes classifier is called 'naive'? State the line from the *'calculate_probability'* function that implements the 'naive' assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on all the 3 datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NB(X,Y):\n",
    "    #class indicies\n",
    "    i_c0 = (Y == 0)\n",
    "    i_c1 = (Y == 1)\n",
    "\n",
    "    X_0 = X[i_c0] #data of class 0\n",
    "    X_1 = X[i_c1] #data of class 1\n",
    "    \n",
    "    prior_dict = calculate_prios(X_0, X_1, X)\n",
    "    \n",
    "    #Calculate statistics for features per class\n",
    "    class_summaries = calculate_MLE(X_0,X_1)\n",
    "    \n",
    "    return prior_dict, class_summaries\n",
    "\n",
    "\n",
    "def test_NB(X, class_summaries, prior_dict):\n",
    "    result = []\n",
    "    for x_test in X:\n",
    "        probs = calculate_probability(x_test, class_summaries, prior_dict)\n",
    "        result.append(list(probs.values()))\n",
    "    return np.array(result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ds_train, ds_test) in enumerate(zip(datasets_train, datasets_test)):\n",
    "    ds_train = datasets_train[i]\n",
    "    ds_test = datasets_test[i]\n",
    "\n",
    "    X = ds_train[0]\n",
    "    Y = ds_train[1]\n",
    "    \n",
    "        \n",
    "    X_test = ds_test[0]\n",
    "    Y_test = ds_test[1]\n",
    "    # 1) train model\n",
    "    prior_dict, class_summaries = train_NB(X,Y)\n",
    "    \n",
    "    # 2) Predict \n",
    "    # a) for test data\n",
    "    posterior = test_NB(X_test,class_summaries, prior_dict )\n",
    "    pred_test = np.argmax(posterior,1)\n",
    "\n",
    "    # b) for training data\n",
    "    posterior = test_NB(X, class_summaries, prior_dict )\n",
    "    pred_train = np.argmax(posterior,1)\n",
    "\n",
    "    \n",
    "    #4) plot predictions\n",
    "    plot_predictions(i,X,Y, X_test, Y_test, pred_train, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** for which datasets did the Naive Bayes classifier perform well? Describe in your own words why this is the case. Why did the Naive Bayes classifier work so badly for the first dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course sklearn package offers an implementation of the Naive Bayes classifier. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for i, (ds_train, ds_test) in enumerate(zip(datasets_train, datasets_test)):\n",
    "    ds_train = datasets_train[i]\n",
    "    ds_test = datasets_test[i]\n",
    "\n",
    "    X = ds_train[0]\n",
    "    Y = ds_train[1]\n",
    "    \n",
    "        \n",
    "    X_test = ds_test[0]\n",
    "    Y_test = ds_test[1]\n",
    "    # 1) train weights\n",
    "    model = GaussianNB()\n",
    "    #let's fit the model (learn its parameters)\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    # 2) Calculate the discriminant function and predict \n",
    "    # a) for test data\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    # b) for training data\n",
    "    y_x = np.dot(W.T, X_b.T)\n",
    "    pred_train = model.predict(X)\n",
    "\n",
    "    \n",
    "    # 4) plot predictions\n",
    "    plot_predictions(i,X,Y, X_test, Y_test, pred_train, pred_test,  plot_nb=model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Example of Naive Bayes for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have understood how Naive Bayes works, let's walk through a text classification example taken from the  exercises notebook accompanying the 'Python Data Science Handbook' [book](https://www.oreilly.com/library/view/python-data-science/9781491912126/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply Naive Bayes classifier to the text classification task. As discussed in class, in text classification the features are related to word counts or frequencies within the documents to be classified.\n",
    "\n",
    "Let's download the 20 Newsgroups corpus and take a look at some target names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity here, we will select just a few of these categories, and download the training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
    "              'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example exntry from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the content of each string into a vector of numbers using the [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) vectorizer and create a pipeline that attaches it to a multinomial naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fir the model on the training data and predict the labels for the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.data, train.target)\n",
    "labels = model.predict(test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of our learned classifier using a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(test.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this simple classifier is able to relatively well seperate the space talk from the computer talk, but it gets confused between talks about religion and Chrisitanity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very cool thing here is that we now have the tools to determine the category for *any* string, using the ``predict()`` method of this pipeline.\n",
    "Here's a quick utility function that will return the prediction for a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('sending a payload to the ISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('discussing islam vs atheism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category('determining the screen resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that this is nothing more sophisticated than a simple probability model for the (weighted) frequency of each word in the string; nevertheless, the result is striking.\n",
    "Even a very naive algorithm, when used carefully and trained on a large set of high-dimensional data, can be surprisingly effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
